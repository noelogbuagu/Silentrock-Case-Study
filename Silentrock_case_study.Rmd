---
title: 'Case Study: Silentrock'
author: "Noel Obinna Ogbuagu"
date: "11/18/2021"
output:
  html_document:
    toc: yes
    df_print: paged
  html_notebook:
    number_sections: no
    toc: yes
    fig_width: 7
    fig_height: 4.5
    theme: readable
    highlight: tango
---


# Introduction

A prop-tech company wants to understand what is so appealing about the short-term housing market in Lagos. For the sake of confidentiality, the name of the company and CEO have been altered. I will focus my analysis on the prices and occupancy of these units while using data visualizations to illustrate my findings.

There are four parts to my script as follows:

* Preparing the Environment
* Data cleaning
* Data analysis
* Data visualization

# Preparing the Environment

Firstly, all the necessary packages and libraries for data cleaning, analysis and visualization need to be installed and loaded. The libraries used are `tidyverse`, `here`, `skimr`, `janitor`, `dplyr`, `lubridate`,`ggplot2` and `ggmap`.

```{r install and load packages, message=FALSE, warning=FALSE}
#Load packages
library("tidyverse") # General analysis
library("here") # data cleaning
library("skimr") # data cleaning
library("janitor") # data cleaning
library("dplyr") #  data manipulation
library("lubridate") # dates
library("ggmap") # maps
library("ggplot2") # visualizations
library("scales") # visualizations
```

Now that the packages are loaded, let's read the data in and take a peek.

```{r load, combine and check data, message=FALSE, warning=FALSE}
# Load the data
ga_listings <- read_csv("listings.csv")
ga_calendar <- read_csv("calendar.csv")
```
Now that we have read in the file, we can view what fields are available in the data. I chose not to combine the dataframes because I decided on joining them when I am visualising.

```{r  message=FALSE, warning=FALSE}
names(ga_listings)
names(ga_calendar)
```
The `ga_listings` contains `12530` listings (=number of rows). The data is organized in a form where each row is a listing and the columns contain information about the listing. While `ga_calendar` contains `4,573,499` rows. Next, it would be best to get a summary of the data.

```{r message=FALSE, warning=FALSE}
# check data
ga_listings %>% 
  glimpse()

# check data
ga_calendar %>% 
  glimpse()
```

# Data Processing

Now that we have an overview of the data, we can proceed to perform some data cleaning. Woah! 74 columns is a lot of data points. Though it's impressive it's important we only work with what's relevant to the business task to be efficient.

To do that, a new data frame `ga_listings_main` will be created. Only attributes that are relevant to the business task will be taken from  `ga_listings` and be added to `ga_listings_main`.

On the other hand, `ga_calendar` contains only 7 attributes. However, `adjusted prices` is redundant and removed since it's the same as `price`.

```{r message=FALSE, warning=FALSE}
ga_listings_main <- ga_listings %>% 
  select(
    id,host_id,host_is_superhost,neighbourhood_cleansed,latitude,longitude,property_type,room_type,accommodates,
    bathrooms_text,bedrooms,beds,price,minimum_nights,maximum_nights
  )

ga_calendar_main <- ga_calendar %>% 
  select(-adjusted_price)
```

Now, let's take a look at the new data frame. 

```{r message=FALSE, warning=FALSE}
ga_listings_main %>% 
  skim_without_charts()

ga_calendar_main %>% 
  skim_without_charts()
```

Now that is done we can focus on renaming and standardizing column names as well as removing duplicate and empty rows. Standardizing column names and filtering.

```{r message=FALSE, warning=FALSE}
ga_listings_main <- ga_listings_main%>%
  remove_empty(which = c("rows","cols")) %>% 
  distinct() %>% 
  rename(
    neighbourhood = neighbourhood_cleansed,
    bathrooms = bathrooms_text
         ) %>% 
  filter(
    maximum_nights<= 180
  ) %>% 
  clean_names()

ga_calendar_main <- ga_calendar_main %>% 
  remove_empty(which = c("rows","cols")) %>% 
  distinct() %>% 
  filter(
    maximum_nights<= 180
  ) %>% 
  clean_names()
  
```

Out of `12,350` listings in `Gauteng` only `3478` qualify as `short lets` *(maximum stay less than six months)*. Now that is done focus can now shift to individual columns. The `price` attribute for `ga_listings_main and ga_calendar_main` shouldn't be categorized as a *character variable*, it should be *numeric*. Also the `$ and ,` need to be removed. 

```{r message=FALSE, warning=FALSE}
ga_listings_main$price = as.numeric(gsub("[\\$,]", "", ga_listings_main$price))
#To confirm
is.numeric(ga_listings_main$price)

ga_calendar_main$price = as.numeric(gsub("[\\$,]", "", ga_calendar_main$price))
#To confirm
is.numeric(ga_calendar_main$price)
```

Next, removing *all text* in the `bathroom_text` column. But first, all fields in the column containing `Half-bath` need to be replaced with `0.5`. Then all text is removed from the column and `bathrooms` is converter to *numeric*.

```{r message=FALSE, warning=FALSE}
ga_listings_main$bathrooms[ga_listings_main$bathrooms=="Half-bath"] <- "0.5"
ga_listings_main$bathrooms = as.numeric(gsub("[\\privatesharedbaths]", "", ga_listings_main$bathrooms))

#To confirm
is.numeric(ga_listings_main$bathrooms)
```

That about wraps it up for data cleaning. Let's head into the analysis!

# Data Analysis

The first thing is to perform some descriptive analysis to get a feel of the data. Lets' take a look at `host_is_superhost` to figure out home many of the hosts are super hosts.

```{r message=FALSE, warning=FALSE}
#Count of super hosts
ga_listings_main %>% 
  group_by(host_is_superhost) %>% 
  drop_na() %>% 
  summarise(number_of_hosts = n(), average_price = mean(price)) %>% 
  mutate(percentage = (number_of_hosts / sum(number_of_hosts))*100) %>% 
  arrange(desc(number_of_hosts))
```

In the last year, Less than 20% of available short term rental property has been listed by `super hosts`. Let's look at where tenants love to stay most and how much it costs to stay in those place on average.

```{r message=FALSE, warning=FALSE}
ga_listings_main %>% 
  group_by(neighbourhood) %>% 
  summarise(number_of_listings = n(), average_price = mean(price)) %>%
  mutate(percentage = (number_of_listings / sum(number_of_listings))*100) %>% 
  arrange(desc(number_of_listings))
```

The`City of Johannesburg` has the highest supply of listings, probably because of high demand. It's likely but not certain and can't tell from the data. However, it's certain that the`City of Johannesburg` has twice the number of listings as the `City of Tshwane`, the location with the second highest number of listings. Let's examine the most popular types of property and rooms next.

```{r message=FALSE, warning=FALSE}
ga_listings_main %>% 
  group_by(neighbourhood, room_type) %>% 
  summarise(
    number_of_listings = n(), average_accommodation = round(mean(accommodates)), average_price = mean(price)
            ) %>% 
  arrange(desc(number_of_listings)) %>% 
  head()
```
It appears that `entire rental units` that can accommodate at least *3* people are the most popular type of property listings in both the `City of Johannesburg` and the `City of Tshwane`. It is at least twice as popular as a `private room in residential home`. 

# Visualisations

I decided to export the necessary files as `Excel` files so visualisations can be executed in `Tableau`. This was done so a comprehensive dashboard can be produced.


```{r}
library("writexl")
write_xlsx(ga_listings_main,"listings.xlsx")
write_xlsx(ga_calendar_main,"calendar.xlsx")

```

The final dashboard produced can be view on my [Tableau profile](https://public.tableau.com/app/profile/noel.obinna.ogbuagu/viz/SilentrockCaseStudy/Dashboard1). Thank you for reaching the end of my analysis. Please I welcome any feedback and I am very open to collaborating!